{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('/Users/alyssa/Documents/FTW/Day_6/census.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 14 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "gender            32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      "income_bracket    32561 non-null object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "census.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label==' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['income'] = census['income'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = census.drop('income',axis=1)\n",
    "y_labels = census['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_labels,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country', 'income_bracket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\"sex\", [\"Female\", \"Male\"], default_value = 0)\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket(\"marital-status\", hash_bucket_size=1000)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket(\"relationship\", hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket(\"education_level\", hash_bucket_size=1000)\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket(\"workclass\", hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\"native-country\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education-num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital-gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital-loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours-per-week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [gender, occupation, marital_status, relationship, education, workclass, native_country,\n",
    "            age, education_num, capital_gain, capital_loss, hours_per_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func=tf.compat.v1.estimator.inputs.pandas_input_fn(x = X_train, y = y_train, batch_size = 100, num_epochs = None, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\dell\\AppData\\Local\\Temp\\tmpu0vhx7um\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_master': '', '_service': None, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_model_dir': 'C:\\\\Users\\\\dell\\\\AppData\\\\Local\\\\Temp\\\\tmpu0vhx7um', '_task_type': 'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025E2ACDCF28>, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_is_chief': True, '_tf_random_seed': None}\n"
     ]
    }
   ],
   "source": [
    "model = tf.compat.v1.estimator.LinearClassifier(feature_columns = feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\dell\\AppData\\Local\\Temp\\tmpu0vhx7um\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 69.3147\n",
      "INFO:tensorflow:global_step/sec: 125.853\n",
      "INFO:tensorflow:step = 101, loss = 669.476 (0.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.108\n",
      "INFO:tensorflow:step = 201, loss = 108.277 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.212\n",
      "INFO:tensorflow:step = 301, loss = 534.312 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.87\n",
      "INFO:tensorflow:step = 401, loss = 144.605 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.838\n",
      "INFO:tensorflow:step = 501, loss = 38.2653 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.377\n",
      "INFO:tensorflow:step = 601, loss = 115.867 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.296\n",
      "INFO:tensorflow:step = 701, loss = 150.222 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.081\n",
      "INFO:tensorflow:step = 801, loss = 41.4633 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.699\n",
      "INFO:tensorflow:step = 901, loss = 180.391 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.615\n",
      "INFO:tensorflow:step = 1001, loss = 58.5201 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.684\n",
      "INFO:tensorflow:step = 1101, loss = 42.8588 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.673\n",
      "INFO:tensorflow:step = 1201, loss = 143.372 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.272\n",
      "INFO:tensorflow:step = 1301, loss = 32.7286 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.68\n",
      "INFO:tensorflow:step = 1401, loss = 59.0123 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.696\n",
      "INFO:tensorflow:step = 1501, loss = 190.453 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.521\n",
      "INFO:tensorflow:step = 1601, loss = 96.9769 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.156\n",
      "INFO:tensorflow:step = 1701, loss = 85.8013 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.981\n",
      "INFO:tensorflow:step = 1801, loss = 31.7447 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.866\n",
      "INFO:tensorflow:step = 1901, loss = 37.9696 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.697\n",
      "INFO:tensorflow:step = 2001, loss = 37.9196 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.853\n",
      "INFO:tensorflow:step = 2101, loss = 31.3852 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.615\n",
      "INFO:tensorflow:step = 2201, loss = 18.3578 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.186\n",
      "INFO:tensorflow:step = 2301, loss = 129.12 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.582\n",
      "INFO:tensorflow:step = 2401, loss = 72.7359 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.261\n",
      "INFO:tensorflow:step = 2501, loss = 112.85 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.172\n",
      "INFO:tensorflow:step = 2601, loss = 39.6291 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.186\n",
      "INFO:tensorflow:step = 2701, loss = 64.8641 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.26\n",
      "INFO:tensorflow:step = 2801, loss = 33.397 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.879\n",
      "INFO:tensorflow:step = 2901, loss = 172.011 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.415\n",
      "INFO:tensorflow:step = 3001, loss = 42.1622 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.696\n",
      "INFO:tensorflow:step = 3101, loss = 33.2583 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.252\n",
      "INFO:tensorflow:step = 3201, loss = 44.4849 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.361\n",
      "INFO:tensorflow:step = 3301, loss = 427.753 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.202\n",
      "INFO:tensorflow:step = 3401, loss = 50.3882 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.884\n",
      "INFO:tensorflow:step = 3501, loss = 35.7544 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.836\n",
      "INFO:tensorflow:step = 3601, loss = 168.161 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.899\n",
      "INFO:tensorflow:step = 3701, loss = 147.953 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.036\n",
      "INFO:tensorflow:step = 3801, loss = 186.618 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.563\n",
      "INFO:tensorflow:step = 3901, loss = 62.8508 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.186\n",
      "INFO:tensorflow:step = 4001, loss = 636.346 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.143\n",
      "INFO:tensorflow:step = 4101, loss = 56.112 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.666\n",
      "INFO:tensorflow:step = 4201, loss = 160.961 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.252\n",
      "INFO:tensorflow:step = 4301, loss = 46.0028 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.322\n",
      "INFO:tensorflow:step = 4401, loss = 35.3193 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.143\n",
      "INFO:tensorflow:step = 4501, loss = 191.707 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.382\n",
      "INFO:tensorflow:step = 4601, loss = 40.0772 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.186\n",
      "INFO:tensorflow:step = 4701, loss = 34.661 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.916\n",
      "INFO:tensorflow:step = 4801, loss = 41.6258 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.707\n",
      "INFO:tensorflow:step = 4901, loss = 30.4159 (0.673 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\dell\\AppData\\Local\\Temp\\tmpu0vhx7um\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 126.944.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x25e33e3a358>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn = input_func, steps = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x = X_test,batch_size = len(X_test), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\dell\\AppData\\Local\\Temp\\tmpu0vhx7um\\model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn = pred_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([0], dtype=int64),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'logistic': array([ 0.28798336], dtype=float32),\n",
       " 'logits': array([-0.90519857], dtype=float32),\n",
       " 'probabilities': array([ 0.71201658,  0.28798333], dtype=float32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.90      0.89      7436\n",
      "          1       0.66      0.64      0.65      2333\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, final_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
